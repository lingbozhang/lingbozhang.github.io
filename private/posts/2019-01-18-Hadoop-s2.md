---
title:  "Hadoop Source Code Analysis-- Part 2"
categories: [Distributed Systems]
tags: [Hadoop]
mathjax: true
---
## Hadoop FileSystem 

### Hahoop FileSystem permission
HDFS FileSystem implements POSIX style permissions, you can find permission actions (enum) defined in <b>FsAction.java</b>:
<details><summary>FsAction.java</summary>
{% highlight java %}
public enum FsAction {
  // POSIX style
  NONE("---"),          // 0b000 
  EXECUTE("--x"),       // 0b001
  WRITE("-w-"),         // 0b010
  WRITE_EXECUTE("-wx"), // 0b011
  READ("r--"),          // 0b100
  READ_EXECUTE("r-x"),  // 0b101
  READ_WRITE("rw-"),    // 0b110
  ALL("rwx");           // 0b111
  ...
}
{% endhighlight %}
</details>
Hadoop FileSystem permission is manipulated by <b>FsPermission.java</b>. It has default permission actions:
<details><summary>FsPermission.java</summary>
{% highlight java %}
...
public static FsPermission getDefault() {
    return new FsPermission((short)00777);
  }

  /**
   * Get the default permission for directory.
   */
  public static FsPermission getDirDefault() {
    return new FsPermission((short)00777);
  }

  /**
   * Get the default permission for file.
   */
  public static FsPermission getFileDefault() {
    return new FsPermission((short)00666);
  }

  /**
   * Get the default permission for cache pools.
   */
  public static FsPermission getCachePoolDefault() {
    return new FsPermission((short)00755);
  }
...
{% endhighlight %}
</details>
User can define permissions actions of a filesystem in the core-site.xml file:
{% highlight XML %}
<configuration>
  <property>
    <name>fs.permissions.umask-mode</name>
    <value>022</value>
    <description>file permission = default-permission&(0b111101101)</description>
  </property>
</configuration>
{% endhighlight %}

### Get file system implementation
In HDFS, the file system implementation is determined by <a href="#URI">URI class</a> and configured by <b>Configuration class</b>. You can get a file system implementation by calling:
{% highlight java %}
FileSystem fs = FileSystem.get(URI uri,Configuration conf);
{% endhighlight %}
The file system implementation is created by <b>createFileSystem method</b> in FileSystem.java which is implemented based on <b>Factory</b> design pattern:
{% highlight java %}
private static FileSystem createFileSystem(URI uri, Configuration conf) throws IOException {
    // clazz is loaded by conf with ClassLoader (see Appendix) and based on the scheme from uri.getScheme() /* LBZ */
    Class<?> clazz = getFileSystemClass(uri.getScheme(), conf);
    FileSystem fs = (FileSystem)ReflectionUtils.newInstance(clazz, conf);
    fs.initialize(uri, conf);
    return fs;
}
{% endhighlight %}

### PacketHeader.java
In Hadoop, data is packaged in packets and then sent through networks. Each packet has a packet header and it is defined in <b>PacketHeader.java</b> file. The packet header data is stored based on [Protocol Buffers](https://developers.google.com/protocol-buffers/).

### DFSPacket.java
Packet is defined in <b>DFSPacket.java</b>, and data are arranged as shown in figure below:

<img src="/assets/DFSPacket.png" alt="drawing"/>

### Block.java
Block is a Hadoop file system primitive identified by variables: blockId, numBytes and generationStamp. Block file name has a following Java regular expression pattern:
{% highlight java %}
"blk_(-??\\d++)$"  //block file name, e.g. blk_1073741825
"blk_(-??\\d++)(_(\\d++)\\.meta)?$" //block meta file name, e.g. blk_1073741825_1001.meta
{% endhighlight %}
where group(1) indicates blockId, group(2) indicates generationStamp.

## Appendix
* <b id="URI">Java URI syntax:</b> scheme:[//[user:password@]host[:port]][/]path[?query][#fragment]
* [<b id="ClassLoader">Java ClassLoader concepts</b>](https://zeroturnaround.com/rebellabs/rebel-labs-tutorial-do-you-really-get-classloaders/)